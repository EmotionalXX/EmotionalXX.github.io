---
layout:     post
title:      [AI工程师]
subtitle:   人工智能
date:       2020-02-20
author:     Mr.Huang
header-img: img/2020.02.03.jpg
catalog: true
tags:
    - 人工智能
    - 机器学习
    - 深度学习
    
---
# 前言

感谢星环科技免费提供的第28期AI工程师认证培训课程，受益无穷！

# 学习内容

	 机器学习建模流程和思路、算法整理、数据预处理、分类回归、树类模型、聚类算法、推荐模型、机器学习模型评估与应用
		
## 机器学习建模流程和思路

机器学习建模流程可按照以下流程：
![3muTKI.jpg](https://s2.ax1x.com/2020/02/20/3muTKI.jpg)

**机器学习建模流程**：数据处理阶段、模型训练阶段和模型应用阶段

**数据处理阶段**：数据获取（理解业务和需求确认）、数据清洗（提升数据质量）、特征工程（提取特征，提升训练模型的效果）、数据整理（整合形成大宽表）

**数据训练阶段**：对之前加工的特征进行描述，评估其权重，必要的时候进行特征降维，之后结合具体的业务问题，选择一个或者几个机器学习算法，通过不断调整
参数反复训练模型，直到模型效果达到预期为止，然后要加载测试数据进行测试，防止发生过拟合问题而全然不知的情况发生。

**数据应用阶段**：在模型经过评估且效果能达到预期之后，我们需要将模型进行部署上线，并且对于线上的测试结果结合实际业务进行解释，看是否能达到业务部门
的目标，以及确认模型的迭代方式和迭代周期。

## 算法整理

**常见时间序列模型**：ARMA模型、ARIMA模型、RNN、LSTM、状态空间模型及Kalman滤波
优点：简单容易实现、快速展示分析成果。
缺点：模型只考虑了时间这一个特征，实际情况中可以能还跟其他特征有着密切的关系，比如是否是节假日，是否有重大活动以及天气情况等。

**常见回归算法**：lasso、ridge、randomforest、xgboost

**常见聚类算法**：Kmeans、混合高斯及层次聚类模型

**机器学习思路**：快速搭建机器学习框架，调优在大框架内逐步完成，先使用简单模型做出效果，然后逐步向业务贴近调整

## 数据预处理

**为什么要进行数据清洗？**
不同行业不同业务场景下产生的数据质量不一，存在编码问题、单位问题、格式问题、缺省值问题等，无法直接使用。
（大概）电力行业的数据质量最高，电商的数据质量最低

**数据清洗的时间**
一般发生在项目初期，同时也伴随着整个项目周期。具体来说，训练人工智能模型的数据源一般来自于数据仓库，而在构建数据仓库的
数据集成阶段会进行一次数据清洗工作，然后在数据建模项目开始的初期会进行数据清洗工作，在模型训练的任何阶段，
只要发现数据异常，都需要进行数据清洗工作。

**数据清洗的作法**
![3mlGJU.png](https://s2.ax1x.com/2020/02/20/3mlGJU.png)
去除或者修改格式和内容有错误的数据、去除或者修改逻辑有错误的数据、去除不需要的数据以及验证数据字段的关联性。

### 数据样本处理

数据样本处理可分为数据采样和样本切分和复制

数据采样，一般在以下两种情况进行，数据倾斜、数据量大（如男女比例为10:1，则需从男女生中合理采样，达到平衡）

数据切分和复制：原始数据80%作为训练集，20%作为测试集。

### 特征工程

数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。

属性是一个数据字段，表述数据对象的一个特征，用来描述一个给定对象的一组属性称为**特征向量**

**特征处理**

![3mY9sg.jpg](https://s2.ax1x.com/2020/02/20/3mY9sg.jpg)


### 衍生特征加工

机器学习建模的过程中最重要的就是特征工程，而特征工程中最重要的就是衍生特征的加工

**衍生特征**：称之为从原始数据中提出人们可识别的特征。
**静态特征**：代表用户不易发生改变的行为习惯
**动态特征**：代表用户最近的一些行为特征，也是模型训练中比较关系的部分。
**组合特征**：通过将部分特征进行组合处理或特征筛选，降低模型复杂度的同时保持模型效果。

### 基于权重的特征选取

利用评价函数选取前10%或前10个特征：

	Person相关系数
	Gini-index基尼系数
	IG信息增益、互信息
	Distance Metrics 距离度量

 PS：通过随机森林算法可得到输出参与模型训练的特征的权重

优点：计算时间上较为高效，对于过拟合问题具有高鲁棒性

缺点：倾向于选择冗余的特征；因为不考虑特征之间的相关性，导致某一个特征分类能力很差，但是和其他特征组合起来效果不错，被筛选掉。（多重共线性）

### 自动特征学习

在实际工程项目中，常常会遇到非结构化数据，通过人为经验很难得到有用的特征，需要借助于自动特征学习的方法

#### 自动特征学习-CNN

卷积神经网络CNN，它可以通过多个神经层，多次特征学习，来提取出一些通过人力无法提取的特征，从而提高基于这类数据源训练的模型的效果。


### 分类回归

### 线性回归

训练模型的过程中，就是用多组（x,y）的值来确定自变量x的参数和常数项的过程。

通过训练集训练得到学习算法，对于新的面积x，则代入算法可求解

**模型定义**

![3m0fgI.jpg](https://s2.ax1x.com/2020/02/20/3m0fgI.jpg)

通过代价函数求解模型权重和偏置量的两种方法：最小二乘法和梯度下降法

**最小二乘法**

![3mBYsP.jpg](https://s2.ax1x.com/2020/02/20/3mBYsP.jpg)

使用参数估计，对w和b求偏导数，即求S最小值。但是在数据量大时无能为力，本质上是无法将大批量数据加载到内存中进行
计算。

**梯度下降法**

梯度下降法可分批次，一轮一轮地计算求解。

梯度下降法的相当于我们下山的过程，每次我们要走一一步下山，寻找最低的地方，那么最可靠的方法便是环顾四周，寻找能--步到达的最低点，持续该过程，最后得到的便是最低点。对于函数而言，便是求得该函数对所有参数(变量)的偏导，每次更新这些参数，直到到达最低点为止，注意这些参数必须在每一轮一起更新， 而不是-一个一个更新。

#### 学习率

![3mDste.jpg](https://s2.ax1x.com/2020/02/20/3mDste.jpg)

#### 线性回归-数据属性转换

对于有序关系的离散属性，可将其通过索引化过程转化为可以比较大小的数字类型，从而参与线性回归模型训练；

对于不可比较大小的离散属性，可将其进行One-Hot编码将其转化为多元向量的形式参与模型训练。

常使用均方差MSE作为模型评估判断模型的效果，MSE越小，代表预测结果和真实结果的误差越小，模型效果越好

### 逻辑回归

逻辑回归是一种广义线性回归，实际上是一种分类器。逻辑回归=线性回归+sigmod函数


### 逻辑回归多分类

1.对于每个类别建立一个二分类器，有此类别的样本标记为1，其他类别样本标记为0
2.修改logistic回归的损失函数，softmax回归

### SVM

支持向量机是一种二分类模型，其基本思想是：对于给定的数据集D，在样本空间中找到一个划分超平面，从而将不同类别的样本分开。

SVM可使用核技巧有效地进行非线性分类，将输入隐式映射到高维特征空间中。

#### 超平面和支持向量

**线性可分**，其实就是用一条线或者一个面，将两类点进行区分，如果区分得开就是线性可分，否则就是线性不可分。
假如是线性可分的话，我们需要通过某种方式找到这样一条线或者一个面，我们称之为**超平面**。
辅助我们找到超平面的一些点或者向量，我们称之为**支持向量**。

#### 带核的SVM

**核函数**：作用就是将在低维空间线性不可分的数据特征映射到高维空间，使其变的线性可分。有可能在高维空间中找到一个特殊的形状，
将高维空间中的数据点进行分类，本质上解决了更复杂的数据分割问题。

#### SVM优缺点及适用场景

**SVM优点**：
1.SVM在解决小样本，韭线性以及高维特征中表现出许多特有的优势。
2.SVM基于有限的样本信息在模型的复杂度和模型准确性之间寻求最佳折中，以获得最好的预测效果。

**SVM缺点**：
1.在数据量大的情况下运算复杂度高，不适合处理过大的数据
2.模型稳定性低，输入的微小变化会使得模型难以收敛。
3.SVM仅直接适用于二分类任务。因此，必须应用将多类任务减少到几个二元问题的算法。

**适用场景**：
目前支持向量机主要应用在模式识别领域中的文本识别，中文分类，人脸识别等，同时也应用到信息过滤等方面。

### 朴素贝叶斯

#### 贝叶斯公式

![3mcRdx.jpg](https://s2.ax1x.com/2020/02/20/3mcRdx.jpg)

#### 贝叶斯优缺点

![3mcLwt.jpg](https://s2.ax1x.com/2020/02/20/3mcLwt.jpg)

显著优点是算法原理简单，模型训练效率高，对缺失值不太敏感；缺点是数据特征相互独立的假设在实际应用中难成立。


# 结语

关于**星环科技-AI工程师培训认证**的学习差不多在此结尾，后续有补充，将会继续更新。

 
 > 本文首次发布于 [Mr.Huang Blog](http://www.huangsz.xyz), 作者 [@(Mr.Huang)](http://github.com/EmotionalXX) ,转载请保留原文链接.







