---
layout:     post
title:      [pandas数据分析库]
subtitle:   pandas学习
date:       2020-02-03
author:     Mr.Huang
header-img: img/2020.1.11.jpg
catalog: true
tags:
    - python
    - pandas
    - matplotlib
    
---
# 前言

观看视频覃秉丰《Python进阶-Pandas数据分析库》学习视频整理笔记

## 学习内容

	pandas基础（Series、DataFram）、选择数据、赋值及操作、pandas处理丢失数据、pandas读取及写入文件、pandas合并、pandas合并、pandas plot
		
### pandas基础


pandas围绕Series和DataFram

Series一维数组，能保存不同种类数据类型，包括字符串、boolean值、数字等都能保存到Series中

Dataframe：二维的表格型数据结构
~~~
Series

dic = {'apple':1,'pen':3,'applepen':5}
s = pd.Series(dic)

结果展示：
apple       1
pen         3
applepen    5
dtype: int64
~~~

~~~
Dataframe

data = {
    'year':[2014,2015,2016,2017],
    'income':[1,3,2,4],
    'pay':[1,1,1,1]
}
df1 = pd.DataFrame(data,index=['No.1','No.2','No.3','No.4'])

结果展示：
      year  income  pay
No.1  2014       1    1
No.2  2015       2    1
No.3  2016       3    1
No.4  2017       4    1

其中，键表示表格中的表头，值表示表头中键对应的值
~~~

	
	df1.columns 列
	df1.index 行
	df1.values 值
	df1.describe() 描述细节（详见下文代码演示）
	df1.T 转置
	df1.sort_index(axis=1) 列排序
	df1.sort_index(axis=0) 行排列
	df1.sort_values(by='income') 对键为‘income’的值进行排序

~~~

print(df1.describe())
结果展示：
              year    income  pay
count     4.000000  4.000000  4.0
mean   2015.500000  2.500000  1.0
std       1.290994  1.290994  0.0
min    2014.000000  1.000000  1.0
25%    2014.750000  1.750000  1.0
50%    2015.500000  2.500000  1.0
75%    2016.250000  3.250000  1.0
max    2017.000000  4.000000  1.0

~~~


### pandas数据选择

~~~
datas = pd.date_range('20200203',periods=6) #定义行索引，从20200203开始，一共6个值
df1 = pd.DataFrame(np.arange(24).reshape((6,4)),index=datas,columns=['A','B','C','D']) #定义列索引
print(df1)
结果展示：
             A   B   C   D
2020-02-03   0   1   2   3
2020-02-04   4   5   6   7
2020-02-05   8   9  10  11
2020-02-06  12  13  14  15
2020-02-07  16  17  18  19
2020-02-08  20  21  22  23
~~~

df1['A'] #将DataFrame的列获取为一个Series  或 使用df1.A   列！！

df1[0:2] #获取表中前两行数据  行！！

df1['20200203':'20200204'] #通过索引取数据  行！！

df1.loc['20200203'] #通过标签选择数据

df1.loc['20200203',['A','B']] #锁定索引'20200203'，提取'A'和'B’两列数据
df1.loc[:,['A','B']] #锁定全部索引，提取A和B两列数据

通过位置选择数据

	df1.iloc[2] #第二行
	df1.iloc[[1,2,4],[1,3]]

# 混合标签位置选择

	df1.ix[2:4,['A','C']]

#提取数据并做判断

	df1.A > 6
	print(df1[df1.A>6]) #只显示Ture 列


### pandas赋值及操作

~~~
df1['E'] = 10 #添加新列，此列全为10
df1['F'] = pd.Series([1,2,3,4,5,6],index=datas) #添加到指定内容到指定列
df1.loc[20200210,['A','B','C']] = [1,2,3] #添加索引为20200210内容，此时D,E,F内容为NAN
~~~

添加新的行内容

	s1  = pd.Series([1,2,3,4,5,6],index = ['A','B','C','D','E','F'])
	s1.name = 'S1'
	df2 = df1.append(s1)

添加新的列内容

	df1.insert(1,'G',df2['E'])
	result:
	A G B C D E F 
	1 5 2 3 4 5 6
	
insert(A,B,C) #A指的是 位置 ，B指的是 名称，C指的是 值

在末尾插入列

	g = df1.pop('G')
	df1.insert(6,'G',g)

删除列 del df1['G'] #删除G列

删除列A和列B df2 = df1.drop(['A','B'],axis = 1) 删除列A和列B


### pandas处理丢失数据

~~~
datas = np.arange(20200203,20200207)
df1 = pd.DataFrame(np.arange(12).reshape(4,3),index=datas,columns=['A','B','C'])
s1 = pd.Series([3,4,6],index=datas[:3])
s2 = pd.Series([32,5,2],index=datas[1:])
print(df1)

结果展示：
          A   B   C
20200203  0   1   2
20200204  3   4   5
20200205  6   7   8
20200206  9  10  11

df1['D'] = s1
df1['E'] = s2
print(df1)

结果展示：
          A   B   C    D     E
20200203  0   1   2  3.0   NaN
20200204  3   4   5  4.0  32.0
20200205  6   7   8  6.0   5.0
20200206  9  10  11  NaN   2.0

df2 = df1.dropna(axis=0,how = 'any') #'how'取值为‘any’和‘all’;any指任意一个，all指全部

结果展示：
          A  B  C    D     E
20200204  3  4  5  4.0  32.0
20200205  6  7  8  6.0   5.0

df2 = df1.dropna(axis=0,how = 'all')
结果展示：
          A   B   C    D     E
20200203  0   1   2  3.0   NaN
20200204  3   4   5  4.0  32.0
20200205  6   7   8  6.0   5.0
20200206  9  10  11  NaN   2.0
~~~

df1.fillna(value=0) #NAN赋值为0

df1.isnull()  #查看是否为NAN

np.any(df1.isnull()) #只要有1个或多个NAN值，则会返回True


### pandas读取及写入文件

~~~
file = pd.read_csv('people.csv',encoding = 'gbk')  #读取csv格式数据，编码方式为gbk
file.iloc[2,0] = '深圳' #修改指定位置的名称为‘深圳’
file,to_csv('people2.csv') #保存为csv格式的文件，文件名'people.csv'
~~~

![lITPPg.jpg](https://s2.ax1x.com/2020/01/12/lITPPg.jpg)


### pandas数据合并

~~~

datas = np.arange(20200203,20200207)
df1 = pd.DataFrame(np.arange(12).reshape(4,3),index=datas,columns=['A','B','C'])
df2 = pd.DataFrame(np.arange(8).reshape(4,2),index=datas,columns=['D','E'])
df3 = pd.DataFrame(np.arange(12).reshape(4,3),index=datas,columns=['F','G','H'])
df4 = pd.concat([df1,df2,df3],axis=1) #横向合并
print(df4)

结果展示：
          A   B   C  D  E  F   G   H
20200203  0   1   2  0  1  0   1   2
20200204  3   4   5  2  3  3   4   5
20200205  6   7   8  4  5  6   7   8
20200206  9  10  11  6  7  9  10  11

~~~

df5 = pd.concat([df1,df2],join='outer') #合并两个表，缺少部分填充NAN

df6 = pd.concat([df1,df2],join='inner') #合并两个表，缺少部分直接去掉

df7 = pd.concat([df1,df2],axis=1,join_axes=[df1.index] #合并并使用df1的index
	
### pandas合并(merge)

~~~
res = pd.merge(left,right,on=['key1','key2'],how='outer') #‘how’默认为inner 
'how' = 'left','right','inner','outer'
'left':只考虑左边的key;'right':只考虑右边的key;'outer':并集U;'inner':交集U
indicator #显示merge信息
~~~


### pandas绘图

~~~
data = pd.Series(np.random.randn(1000),index = np.arange(1000))
data = data.cumsum()
data.plot()
plt.show()
~~~

结果展示：
![10yfbT.jpg](https://s2.ax1x.com/2020/02/03/10yfbT.jpg)

~~~
data = pd.DataFrame(np.random.randn(1000,4),index=np.arange(1000),columns=['A','B','C','D'])
data = data.cumsum()
print(data.head())
data.plot()
plt.show()
~~~

结果展示：

~~~
          A         B         C         D
0 -2.448184  1.313661  1.569665  1.893973
1 -1.704221  1.974372  2.337107  2.318515
2 -0.117956  2.133727  1.829862  2.339920
3  1.838135  0.563140  1.897035  0.897317
4  3.967883  0.236015  3.222193  2.477303
~~~
![10y7G9.jpg](https://s2.ax1x.com/2020/02/03/10y7G9.jpg)


~~~
data = pd.DataFrame(np.random.randn(1000,4),index=np.arange(1000),columns=['A','B','C','D'])
ax = data.plot.scatter(x='A',y='B',color='Blue',label='class1')
data.plot.scatter(x='A',y='C',color = 'Green',label = 'class2',ax=ax)
plt.show()
~~~
结果展示：
![1066oD.jpg](https://s2.ax1x.com/2020/02/03/1066oD.jpg)


# 结语

关于**python-pandas**的学习差不多在此结尾，后续有补充，将会继续更新。

 
 > 本文首次发布于 [Mr.Huang Blog](http://www.huangsz.xyz), 作者 [@(Mr.Huang)](http://github.com/EmotionalXX) ,转载请保留原文链接.







