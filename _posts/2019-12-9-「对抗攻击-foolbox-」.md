---
layout:     post
title:      利用foolbox进行对抗样本的生成
subtitle:   环境:Ubuntu18.04 TensorFlow1.13-CPU python3.7 
date:       2019-12-10
author:     Mr.Huang
header-img: img/2019.12.10.jpg
catalog: true
tags:
    - 对抗机器学习
    - vgg19
    - foolbox
    - python
---

# 前言
本节内容主要是利用虚拟机内的 **Ubuntu18.04** 和 **tensorflow1.13** 进行操作。

网络模型是VGG19，也就是ILSVRC14中脱颖而出的网络模型。

# 正文


## foolbox简介 


![Q0shOe.jpg](https://s2.ax1x.com/2019/12/10/Q0shOe.jpg)

**FoolBox**包含主流数十种白盒黑盒攻击算法，兼容TensorFlow、Pytorch、Keras、Caffe等多种主流深度学习框架，是一种成熟的一站式、接口式攻击平台。


	pip install foolbox==1.8.0

## Foolbox实战


感谢@[Icoding_F2014](https://blog.csdn.net/jmh1996/article/details/101713548)

### 获取训练好的模型文件

**VGG模型文件：** <http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz/>

解压得到vgg_19.ckpt文件


### 加载模型

先创建一个类NodeLookup来将softmax概率值映射到标签上,然后创建一个函数create_graph()来读取模型。详细代码如下：

```
__author__ = 'dk'
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.contrib.slim.nets import vgg
import numpy as np
import foolbox
images = tf.placeholder(tf.float32, shape=(None, 224, 224, 3))
preprocessed = images - [123.68, 116.78, 103.94]
logits, _ = vgg.vgg_19(preprocessed, is_training=False)
restorer = tf.train.Saver(tf.trainable_variables())

image, label = foolbox.utils.imagenet_example()
print('label',label)
with foolbox.models.TensorFlowModel(images, logits, (0, 255)) as model:
    restorer.restore(model.session, 'C:\\Users\\dk\\Downloads\\vgg_19_2016_08_28\\vgg_19.ckpt')
    predict_label = np.argmax(model.predictions(image))
    print('predict label',predict_label)

    fmodel = model
    # apply attack on source image
    attack  = foolbox.attacks.FGSM(fmodel)
    adversarial = attack(image, 281)
    difference = (adversarial - image)%256

    adv_label = np.argmax(fmodel.predictions(adversarial))
    print('adversarial class', adv_label)
    plt.subplot(1,3,1)
    plt.title('origin predict label %s'%281)
    plt.imshow(np.asarray(image,dtype=np.int))

    plt.subplot(1,3,2)
    plt.title('adv image label %s'%adv_label)
    plt.imshow(np.asarray(adversarial,dtype=np.int))

    plt.subplot(1,3,3)
    plt.title('difference image')
    plt.imshow(np.asarray(difference,dtype= np.int))
    plt.show()

```


### 测试数据

攻击样例中给出的橘猫图片

	predict label 281
	adversarial class 278


测试结果如下：

[![Q0yukR.md.jpg](https://s2.ax1x.com/2019/12/10/Q0yukR.md.jpg)](https://imgse.com/i/Q0yukR)




	


# 结语

关于**adversarial attacks**的测试就这样简单的介绍完了。

 
 > 本文首次发布于 [Mr.Huang Blog](http://www.huangsz.xyz), 作者 [@(Mr.Huang)](http://github.com/EmotionalXX) ,转载请保留原文链接.
